{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GIT_BrainMusic_Train_polyphony_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brainmusic/models/blob/master/BrainMusic_Train_polyphony_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQgJ6x2UtPCs",
        "colab_type": "text"
      },
      "source": [
        "# Environment Setup\n",
        "Install magenta and fluidsynth, a sequence synthesis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uq7cNslgQQS",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install\n",
        "\n",
        "#@markdown Install magenta and fluidsynth as a synthesizer to listen de audios.\n",
        " #@markdown Magenta is compatible with both Python 2 and 3.\n",
        " #@markdown This take some time, specially for fluidsynth instalation\n",
        "\n",
        "!pip install magenta\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 \\\n",
        "fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi\n",
        "# Hack to allow python to pick up the newly-installed fluidsynth lib. \n",
        "# This is only needed for the hosted Colab environment.\n",
        "import ctypes.util\n",
        "orig_ctypes_util_find_library = ctypes.util.find_library\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return orig_ctypes_util_find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx1ptrjdi3A4",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Drive Setup\n",
        "#@markdown If your training sample is in google drive you need to connect it. \n",
        "#@markdown You can also upload the data to a temporary folder but it will be \n",
        "#@markdown lost when the session is closed.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O976jh2chLLp",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Import Dependencies\n",
        "#@markdown Import libraries from Magenta, Tensorflow and Numpy\n",
        "\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import magenta.music as mm\n",
        "import magenta\n",
        "from magenta.scripts import convert_dir_to_note_sequences\n",
        "from magenta.models.polyphony_rnn import *\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-JSJ5d8xkXJ",
        "colab_type": "text"
      },
      "source": [
        "# Sample adaptation\n",
        "\n",
        "Magenta does not work directly with Midi files but with NoteSequences, so the first step to create the sample is to convert the Midi files into Note sequences files and pack them as tfrecord to work with them fast and efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqVTh_Xs56vN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "You need to define the folder with the midi files, as well as the\n",
        "folder in which the notesequence will be saved. Change the routes from below to your own folders. The output of this step (notesequences)  can be saved directly as a temporary file, e.g. /tmp/notesequences_Happy.tfrecord \\ instead of on the drive, since after the next step in which the sample is split it would no longer be necessary.  \n",
        "\n",
        "Tips for novice: You can see the path of the folder to the left in files and with the mouse button select \"copy path\". As the route usually contains   \"My drive\" remember to enter \"\\\\\"  in the middel as \"My \\ drive\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksd7ZJLG55Ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!convert_dir_to_note_sequences \\\n",
        "--input_dir=/content/drive/My\\ Drive/brain_music/data/audios/Happy \\\n",
        "--output_file=/content/drive/My\\ Drive/brain_music/data/audios/noteSequences/notesequences_Happy.tfrecord \\\n",
        "--log=INFO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMfaieWF6tLe",
        "colab_type": "text"
      },
      "source": [
        "Now you are ready to separate your sample between train and test. The percentage you leave in the test for evaluate your model is defined with the eval ratio argument. For example with a eval ratio equal to 10%, the 90% of the sample will be saved in the traing collection, while the remaining 10% will be stored as evaluation sample.\n",
        "\n",
        "The input for this step must match the one defined as output in the previous step.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIC9rvO2FfiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test and train sample split wih 10% ratio\n",
        "!polyphony_rnn_create_dataset \\\n",
        "--input=/content/drive/My\\ Drive/brain_music/data/audios/noteSequences/notesequences_Happy.tfrecord \\\n",
        "--output_dir=/content/drive/My\\ Drive/brain_music/RNN/sample/Happy \\\n",
        "--eval_ratio=0.10 \\\n",
        "--config='polyphony'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj5VWN5k87qM",
        "colab_type": "text"
      },
      "source": [
        "If the cell has been executed correctly, you have to have two files saved in the output_dir, both in tfrecord format, one with the training sample and one with the eval sample. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0-HHl_H5bKE",
        "colab_type": "text"
      },
      "source": [
        "# Model Training\n",
        "Now you are ready to train your model!\n",
        "\n",
        "This step can take a long time and depending on how large your database is and the number of layers and their size, you may get a memory error, or lose the connection to the GPU.\n",
        "\n",
        "We recommend you to start with a small sample and a light model for example a bach size of 64 batch_size=64 and two LSTM rnn layers of 64, \"batch_size=64,rnn_layer_sizes=[64,64]\" and incorporate more complexity little by little. If you save the checkpoints you can re-launch the training at the point where you left the previous session, this is especially interesting if you lose the web connection or your session closes unexpectedly.  \n",
        "\n",
        "\n",
        "To train the model you can define the following parameters: \n",
        "* **run_dir** is the directory where checkpoints and TensorBoard data will be stored.\n",
        "* **sequence_example_file** is the TFRecord file with the train sample, the folder  must be the same as the one defined in output_dir in the previous step . \n",
        "* **num_training_steps** is an optional parameter for how many update steps to take before exiting the training loop. By default, training will run continuously until manually terminated.\n",
        "* **hparams** is another optional parameter that specifies the hyperparameters you want to use. By default polyphony rnn model use this configuration \n",
        "* **dropout_keep_prob** Dropout is a regularization method to reduce overfitting and improving model performance. The dropout select randomly a % of neurons in the LSTM units thats are probabilistically excluded from activation and weight updates while training the model. \n",
        "* **learning_rate** The learning rate controls how quickly or slowly a neural network model learns. This value are ussually between 0.0 and 1.0, a learning rate too small may result in a long training process that could get stuck, whereas a value too large may result in an unstable training process.\n",
        "\n",
        "By default polyphony_rnn model use this configuration: \n",
        "* batch_size=64,\n",
        "* rnn_layer_sizes=[256, 256, 256]\n",
        "* dropout_keep_prob=0.5\n",
        "* learning_rate=0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9LAnyFhPUOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train the model!\n",
        "!polyphony_rnn_train \\\n",
        "--run_dir=/content/drive/My\\ Drive/brain_music/RNN/modelos/polyphony/happy/run2 \\\n",
        "--sequence_example_file=/content/drive/My\\ Drive/brain_music/RNN/sample/Happy/training_poly_tracks.tfrecord \\\n",
        "--num_training_steps=10000 \\\n",
        "--hparams=\"batch_size=64,rnn_layer_sizes=[128,128,128]\" \\\n",
        "--config='polyphony' \\\n",
        "--num_checkpoints=10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRMi2Cd4MleX",
        "colab_type": "text"
      },
      "source": [
        "When you consider that the model is sufficiently tuned you can keep it in a bundle file. This allows you to import the trained model at any time and use it to create new sequences. To save it you have to call the same function of the previous step polyphony_rnn_generate, but changing some of the parameterization\n",
        "\n",
        "*   the run directory has to be the same as in previous step \n",
        "*   hparam must also be the same as those defined in the training. \n",
        "*   bundle_file is the path where to save the file with the model.mag\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilUtMeudzrHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save your model \n",
        "!melody_rnn_generate \\\n",
        "--run_dir=/content/drive/My\\ Drive/brain_music/RNN/modelos/polyphony/happy/run2 \\\n",
        "--hparams=\"batch_size=64,rnn_layer_sizes=[128,128,128]\" \\\n",
        "--bundle_file=/content/braimusic_poly_happy_rnn.mag \\\n",
        "--save_generator_bundle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6O27QcYPMQS",
        "colab_type": "text"
      },
      "source": [
        "# Sample adaptation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGtU72fWxQzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "primer_midi=('/content/drive/My Drive/brain_music/data/audios/Happy/temp110__1.mid')\n",
        "input_sequence=mm.midi_file_to_note_sequence(primer_midi)\n",
        "start = magenta.music.sequences_lib.extract_subsequence(input_sequence,0,12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byo0QUvHnRUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generar nuevas canciones con el modelo entrenado a partir de inicio midi\n",
        "!melody_rnn_generate \\\n",
        "--config='attention_rnn' \\\n",
        "--run_dir=/content/drive/My\\ Drive/brain_music/RNN/modelos/polyphony \\\n",
        "--output_dir=/content/drive/My\\ Drive/brain_music/data/audios/creacionesAI/polyphony_train \\\n",
        "--num_outputs=1 \\\n",
        "--num_steps=600 \\\n",
        "--primer_midi=/content/drive/My\\ Drive/brain_music/OmensOfLove.mid \\\n",
        "--condition_on_primer=true \\\n",
        "--temperature=0.9\n",
        "--inject_primer_during_generation=false\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5kAVmVHOMx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mm.plot_sequence(input_sequence)\n",
        "primer_midi_new=('/tmp/rnn/generated2/2019-11-26_220959_1.mid')\n",
        "input_sequence_new=mm.midi_file_to_note_sequence(primer_midi_new)\n",
        "mm.plot_sequence(input_sequence_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIV4Ipj45poj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate a  some new sequences with the train model\n",
        "!polyphony_rnn_generate \\\n",
        "--config='polyphony_rnn ' \\\n",
        "--bundle_file=/content/braimusic_poly_happy_rnn.mag  \\\n",
        "--hparams=\"batch_size=64,rnn_layer_sizes=[128,128,128]\" \\\n",
        "--output_dir=/content/drive/My\\ Drive/brain_music/data/audios/creacionesAI/polyphony_pretrain \\\n",
        "--num_outputs=10 \\\n",
        "--num_steps=600 \\\n",
        "--primer_pitches=\"[67,64,60]\" \\\n",
        "--condition_on_primer=true \\\n",
        "--inject_primer_during_generation=false"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x6FVbWFbOmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!polyphony_rnn_generate \\\n",
        "--config='polyphony_rnn ' \\\n",
        "--bundle_file=/content/polyphony_rnn.mag  \\\n",
        "--hparams=\"batch_size=64,rnn_layer_sizes=[128,128,128]\" \\\n",
        "--output_dir=/content/drive/My\\ Drive/brain_music/data/audios/creacionesAI/polyphony_pretrain \\\n",
        "--num_outputs=10 \\\n",
        "--num_steps=600 \\\n",
        "--primer_pitches=\"[67,64,60]\" \\\n",
        "--condition_on_primer=true \\\n",
        "--inject_primer_during_generation=false"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmtEnL2u5ERV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#modelo pre-entrenado\n",
        "from magenta.models.polyphony_rnn import polyphony_sequence_generator\n",
        "mm.notebook_utils.download_bundle('polyphony_rnn.mag', '/content/')\n",
        "bundle_polyphony = mm.sequence_generator_bundle.read_bundle_file('/content/polyphony_rnn.mag')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "behva3rM9wwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from magenta.models.performance_rnn import *\n",
        "#modelo pre-entrenado\n",
        "from magenta.models.performance_rnn import performance_sequence_generator\n",
        "mm.notebook_utils.download_bundle('performance.mag', '/content/')\n",
        "bundle_performance = mm.sequence_generator_bundle.read_bundle_file('/content/performance.mag')\n",
        "\n",
        "mm.notebook_utils.download_bundle('performance_with_dynamics.mag', '/content/')\n",
        "bundle_performance_with_dynamics = mm.sequence_generator_bundle.read_bundle_file('/content/performance_with_dynamics.mag')\n",
        "\n",
        "\n",
        "mm.notebook_utils.download_bundle('performance_with_dynamics_and_modulo_encoding.mag', '/content/')\n",
        "bundle_performance_with_dynamics_and_modulo_encoding = mm.sequence_generator_bundle.read_bundle_file('/content/performance_with_dynamics_and_modulo_encoding.mag')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN5Gv8O1PokU",
        "colab_type": "code",
        "outputId": "86a2c9d4-4102-4a70-885a-88312aa34150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!performance_rnn_generate \\\n",
        "--config='performance_rnn ' \\\n",
        "--bundle_file=/content/performance.mag  \\\n",
        "--hparams=\"batch_size=64,rnn_layer_sizes=[128,128,128]\" \\\n",
        "--output_dir=/content/drive/My\\ Drive/brain_music/data/audios/creacionesAI/performance_pretrain \\\n",
        "--num_outputs=10 \\\n",
        "--num_steps=6000 \\\n",
        "--primer_pitches=\"[67,64,60]\" \\\n",
        "--condition_on_primer=true \\\n",
        "--inject_primer_during_generation=false"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1130 17:02:59.275494 139954035664768 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/pipelines/statistics.py:131: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W1130 17:03:00.009083 139954035664768 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/music/note_sequence_io.py:60: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1130 17:03:00.011415 139954035664768 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W1130 17:03:00.399406 139954035664768 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/models/performance_rnn/performance_rnn_generate.py:290: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W1130 17:03:00.400013 139954035664768 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/models/performance_rnn/performance_rnn_generate.py:257: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W1130 17:03:00.400247 139954035664768 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/music/sequence_generator_bundle.py:30: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1130 17:03:00.456800 139954035664768 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/models/performance_rnn/performance_rnn_generate.py:159: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "W1130 17:03:00.457741 139954035664768 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/models/performance_rnn/performance_rnn_generate.py:237: The name tf.logging.debug is deprecated. Please use tf.compat.v1.logging.debug instead.\n",
            "\n",
            "W1130 17:03:00.488025 139954035664768 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/music/model.py:69: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-11-30 17:03:00.489284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-11-30 17:03:00.503291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-30 17:03:00.503931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-11-30 17:03:00.504210: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-11-30 17:03:00.505864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-11-30 17:03:00.507579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-11-30 17:03:00.507949: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-11-30 17:03:00.509551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-11-30 17:03:00.510271: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-11-30 17:03:00.513451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-11-30 17:03:00.513567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-30 17:03:00.514144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-30 17:03:00.514669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-11-30 17:03:00.515028: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2019-11-30 17:03:00.519626: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000150000 Hz\n",
            "2019-11-30 17:03:00.520115: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cd82b496c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-11-30 17:03:00.520144: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-11-30 17:03:00.608933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-30 17:03:00.609971: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cd82b4aa00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-11-30 17:03:00.610006: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2019-11-30 17:03:00.610262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-30 17:03:00.611007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-11-30 17:03:00.611129: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-11-30 17:03:00.611150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-11-30 17:03:00.611166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-11-30 17:03:00.611181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-11-30 17:03:00.611196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-11-30 17:03:00.611211: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-11-30 17:03:00.611226: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-11-30 17:03:00.611329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-30 17:03:00.612313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-30 17:03:00.613138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-11-30 17:03:00.613241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-11-30 17:03:00.614878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-11-30 17:03:00.614908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-11-30 17:03:00.614919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-11-30 17:03:00.615019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-30 17:03:00.615580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-30 17:03:00.616139: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-11-30 17:03:00.616178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "W1130 17:03:00.616920 139954035664768 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/music/model.py:70: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
            "\n",
            "W1130 17:03:00.660459 139954035664768 meta_graph.py:887] The saved meta_graph is possibly from an older release:\n",
            "'model_variables' collection should be of type 'byte_list', but instead is of type 'node_list'.\n",
            "I1130 17:03:00.662645 139954035664768 saver.py:1284] Restoring parameters from /tmp/tmp9ZiQU3/model.ckpt\n",
            "W1130 17:03:00.728817 139954035664768 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/music/sequence_generator.py:159: The name tf.gfile.DeleteRecursively is deprecated. Please use tf.io.gfile.rmtree instead.\n",
            "\n",
            "I1130 17:03:00.732981 139954035664768 performance_sequence_generator.py:229] Need to generate 5949 more steps for this sequence, will try asking for 3570 RNN steps\n",
            "2019-11-30 17:03:00.765220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "I1130 17:03:11.330163 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -8557.513672 \n",
            "W1130 17:03:11.368462 139954035664768 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/magenta/music/midi_io.py:214: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
            "\n",
            "I1130 17:03:11.372337 139954035664768 performance_sequence_generator.py:229] Need to generate 5949 more steps for this sequence, will try asking for 3570 RNN steps\n",
            "I1130 17:03:20.951191 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -8427.035156 \n",
            "I1130 17:03:21.050529 139954035664768 performance_sequence_generator.py:229] Need to generate 5949 more steps for this sequence, will try asking for 3570 RNN steps\n",
            "I1130 17:03:30.871520 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -8960.325195 \n",
            "I1130 17:03:30.872366 139954035664768 performance_sequence_generator.py:229] Need to generate 565 more steps for this sequence, will try asking for 339 RNN steps\n",
            "I1130 17:03:33.471267 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -9853.680664 \n",
            "I1130 17:03:33.480103 139954035664768 performance_sequence_generator.py:229] Need to generate 80 more steps for this sequence, will try asking for 48 RNN steps\n",
            "I1130 17:03:35.598186 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -9969.555664 \n",
            "I1130 17:03:35.607053 139954035664768 performance_sequence_generator.py:229] Need to generate 33 more steps for this sequence, will try asking for 20 RNN steps\n",
            "I1130 17:03:37.403770 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -10022.867188 \n",
            "I1130 17:03:37.413249 139954035664768 performance_sequence_generator.py:229] Need to generate 12 more steps for this sequence, will try asking for 8 RNN steps\n",
            "I1130 17:03:39.206124 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -10041.431641 \n",
            "I1130 17:03:39.215262 139954035664768 performance_sequence_generator.py:229] Need to generate 6 more steps for this sequence, will try asking for 4 RNN steps\n",
            "I1130 17:03:41.012487 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -10050.839844 \n",
            "I1130 17:03:41.119384 139954035664768 performance_sequence_generator.py:229] Need to generate 5949 more steps for this sequence, will try asking for 3570 RNN steps\n",
            "I1130 17:03:50.642728 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -8825.682617 \n",
            "I1130 17:03:50.887423 139954035664768 performance_sequence_generator.py:229] Need to generate 5949 more steps for this sequence, will try asking for 3570 RNN steps\n",
            "I1130 17:04:00.506525 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -8676.171875 \n",
            "I1130 17:04:00.507546 139954035664768 performance_sequence_generator.py:229] Need to generate 166 more steps for this sequence, will try asking for 100 RNN steps\n",
            "I1130 17:04:02.412666 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -8903.416016 \n",
            "I1130 17:04:02.420593 139954035664768 performance_sequence_generator.py:229] Need to generate 38 more steps for this sequence, will try asking for 23 RNN steps\n",
            "I1130 17:04:04.095160 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -8967.233398 \n",
            "I1130 17:04:04.104341 139954035664768 performance_sequence_generator.py:229] Need to generate 15 more steps for this sequence, will try asking for 9 RNN steps\n",
            "I1130 17:04:05.738611 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -8993.335938 \n",
            "I1130 17:04:05.843931 139954035664768 performance_sequence_generator.py:229] Need to generate 5949 more steps for this sequence, will try asking for 3570 RNN steps\n",
            "I1130 17:04:15.420768 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -8189.139648 \n",
            "I1130 17:04:15.470272 139954035664768 performance_sequence_generator.py:229] Need to generate 5949 more steps for this sequence, will try asking for 3570 RNN steps\n",
            "I1130 17:04:25.106055 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -8656.208008 \n",
            "I1130 17:04:25.188571 139954035664768 performance_sequence_generator.py:229] Need to generate 5949 more steps for this sequence, will try asking for 3570 RNN steps\n",
            "I1130 17:04:34.616327 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -8567.094727 \n",
            "I1130 17:04:34.646241 139954035664768 performance_sequence_generator.py:229] Need to generate 5949 more steps for this sequence, will try asking for 3570 RNN steps\n",
            "I1130 17:04:44.018389 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -8561.169922 \n",
            "I1130 17:04:44.067003 139954035664768 performance_sequence_generator.py:229] Need to generate 5949 more steps for this sequence, will try asking for 3570 RNN steps\n",
            "I1130 17:04:54.277100 139954035664768 events_rnn_model.py:381] Beam search yields sequence with log-likelihood: -8672.170898 \n",
            "I1130 17:04:54.373383 139954035664768 performance_rnn_generate.py:252] Wrote 10 MIDI files to /content/drive/My Drive/brain_music/data/audios/creacionesAI/performance_pretrain\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}